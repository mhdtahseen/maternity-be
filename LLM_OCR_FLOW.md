# LLM and OCR Flow Documentation

## Current Architecture

### üìã Current Flow (Before Changes)

```
Medical Document Upload
        ‚Üì
File Storage (MinIO)
        ‚Üì
[DOCUMENT_OCR Queue]
        ‚Üì
OCR Adapter
‚îú‚îÄ Primary Provider (configured: tesseract, qwen_vision, or stub)
‚îú‚îÄ Backup Provider (optional fallback)
‚îî‚îÄ Compare Mode (optional: test both providers)
        ‚Üì
OCR Text Extraction
        ‚Üì
Store in: document.ocrText + document.structuredJson.ocrMeta
        ‚Üì
[DOCUMENT_LLM Queue]
        ‚Üì
OpenRouter Client (GPT via OpenRouter)
‚îú‚îÄ Input: OCR extracted text
‚îú‚îÄ Task: Medical document analysis
‚îî‚îÄ Output: Structured JSON extraction
        ‚Üì
Structured Output:
‚îú‚îÄ Document authenticity (score + reasons)
‚îú‚îÄ Document classification (type: PRESCRIPTION, LAB_REPORT, etc.)
‚îú‚îÄ Extracted data (doctor, hospital, medicines, etc.)
‚îú‚îÄ humanSummary (patient-friendly 4-8 sentences)
‚îú‚îÄ tags (auto-generated)
‚îî‚îÄ timelineEvents (extracted events with timestamps)
        ‚Üì
[DOCUMENT_PERSIST Queue]
        ‚Üì
Save to Database (MedicalDocument)
        ‚Üì
Additional Processors (optional):
‚îú‚îÄ Document Normalize
‚îú‚îÄ Timeline Build
‚îú‚îÄ Search Index
‚îî‚îÄ Antivirus Scan
```

---

## Current Providers

### 1. **Tesseract OCR** (Traditional)

- **Type**: Local optical character recognition
- **Pros**: Free, works offline, handles PDFs natively
- **Cons**: Lower accuracy than vision models, struggles with handwriting
- **Config**: `OCR_PROVIDER=tesseract`

### 2. **Qwen Vision** (Current Vision Model)

- **Type**: Alibaba's Qwen Vision model via OpenRouter
- **Pros**: Better accuracy, handles complex layouts, understands medical content
- **Cons**: Requires API key, slower, costs money
- **Config**: `OCR_PROVIDER=qwen_vision`
- **Details**:
  - Model: `qwen/qwen3-vl-235b-a22b-thinking`
  - Max pages: 2 (configurable 1-6)
  - Timeout: 45s (configurable 5s-120s)

### 3. **Stub** (Placeholder)

- **Type**: No-op for testing
- **Config**: `OCR_PROVIDER=stub`

---

## LLM Analysis Pipeline

### OpenRouter Client

- **API**: OpenRouter (multi-model LLM API)
- **Default Model**: `openai/gpt-oss-120b` (or GPT-4o)
- **Task**: Medical document analysis & extraction
- **Input**: OCR text
- **Output**: Structured JSON with:
  - Medical data extraction
  - Authenticity verification
  - Document classification
  - Patient-friendly summaries
  - Timeline events

---

## Configuration Environment Variables

```env
# OCR Configuration
OCR_PROVIDER=qwen_vision                           # Primary OCR provider
OCR_BACKUP_PROVIDER=tesseract                      # Fallback OCR provider (optional)
OCR_COMPARE_MODE=false                             # Test both providers (debug mode)
OCR_QWEN_MAX_PAGES=2                               # Max pages for Qwen (1-6)
OCR_QWEN_TIMEOUT_MS=45000                          # Timeout in milliseconds

# Vision Model (Qwen Vision)
OPENROUTER_QWEN_API_KEY=sk-...                     # Qwen API key (or uses OPENROUTER_API_KEY)
QWEN_VISION_MODEL=qwen/qwen3-vl-235b-a22b-thinking # Qwen model

# LLM / GPT Configuration
OPENROUTER_API_KEY=sk-...                          # OpenRouter API key
OPENROUTER_MODEL=openai/gpt-oss-120b               # LLM model for analysis
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1  # OpenRouter endpoint
OPENROUTER_HTTP_REFERER=                           # Optional: your app URL
OPENROUTER_X_TITLE=Maternity Journal               # Optional: app name

# For OpenRouter API compatibility
OPENROUTER_HTTP_REFERER=https://maternityjournal.com
OPENROUTER_X_TITLE=Maternity Journal
```

---

## Current Job Pipeline

1. **DocumentOcrProcessor** - Extracts text from images/PDFs
2. **DocumentLlmProcessor** - Analyzes extracted text with GPT
3. **DocumentPersistProcessor** - Saves results to database
4. **DocumentNormalizeProcessor** - Cleans and normalizes data
5. **TimelineBuildProcessor** - Creates timeline events
6. **SearchIndexProcessor** - Indexes for search
7. **DocumentAntivisrusProcessor** - Scans files

---

## Files Involved

- **OCR Integration**: [src/integrations/ocr/ocr.adapter.ts](src/integrations/ocr/ocr.adapter.ts)
- **LLM Integration**: [src/integrations/llm/openrouter.client.ts](src/integrations/llm/openrouter.client.ts)
- **OCR Processor**: [src/jobs/processors/document-ocr.processor.ts](src/jobs/processors/document-ocr.processor.ts)
- **LLM Processor**: [src/jobs/processors/document-llm.processor.ts](src/jobs/processors/document-llm.processor.ts)
- **AI Config**: [src/config/ai.config.ts](src/config/ai.config.ts)

---

## Recommended Changes for Vision + GPT Flow

### Option 1: Use Claude Vision + GPT (Recommended)

```
Medical Document
    ‚Üì
Claude Vision API (for OCR)  ‚Üê Better accuracy than Qwen
    ‚Üì
GPT-4o (for summarization)   ‚Üê Current LLM flow
    ‚Üì
Database
```

### Option 2: Use Qwen Vision + GPT (Current Setup)

```
Medical Document
    ‚Üì
Qwen Vision API (for OCR)
    ‚Üì
GPT (for summarization)
    ‚Üì
Database
```

### Implementation Changes Required:

1. ‚úÖ Set `OCR_PROVIDER=qwen_vision` (or add Claude Vision support)
2. ‚úÖ Configure `OPENROUTER_MODEL` to GPT model (e.g., `openai/gpt-4o`)
3. ‚úÖ Keep LLM pipeline as-is (already handles summarization)
4. ‚ö†Ô∏è Optional: Add Claude Vision adapter for better accuracy

---

## Error Handling & Fallback

- **OCR Fails**: Falls back to backup provider or marks document for review
- **LLM Fails**: Infers document type from OCR text, creates fallback tags, marks for review
- **Both Fail**: Document stored with error metadata for manual review
